{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.31M/5.31M [00:04<00:00, 1.24MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load YOLOv8 model (classification mode)\n",
    "model = YOLO(\"yolov8n-cls.pt\")  # Using the pre-trained nano model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.84 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.55  Python-3.11.8 torch-2.2.2+cpu CPU (12th Gen Intel Core(TM) i5-1240P)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=drawings, epochs=10, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train2\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\train... found 40 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\val... found 20 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\train2', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\train... 40 images, 0 corrupt: 100%|██████████| 40/40 [00:00<00:00, 355.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\val... 20 images, 0 corrupt: 100%|██████████| 20/20 [00:00<00:00, 810.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G     0.7762          8        224: 100%|██████████| 3/3 [00:02<00:00,  1.26it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.65          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G     0.7618          8        224: 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.65          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G     0.7176          8        224: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.7          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G     0.6902          8        224: 100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.8          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      0.677          8        224: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.85          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G     0.6441          8        224: 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.9          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.5958          8        224: 100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.9          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.6326          8        224: 100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.9          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G      0.616          8        224: 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.9          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G     0.6171          8        224: 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.9          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.009 hours.\n",
      "Optimizer stripped from runs\\classify\\train2\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from runs\\classify\\train2\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating runs\\classify\\train2\\weights\\best.pt...\n",
      "Ultralytics 8.3.55  Python-3.11.8 torch-2.2.2+cpu CPU (12th Gen Intel Core(TM) i5-1240P)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\train... found 40 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\val... found 20 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.9          1\n",
      "Speed: 0.0ms preprocess, 9.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000028FF134FED0>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.949999988079071\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.8999999761581421, 'metrics/accuracy_top5': 1.0, 'fitness': 0.949999988079071}\n",
       "save_dir: WindowsPath('runs/classify/train2')\n",
       "speed: {'preprocess': 0.0, 'inference': 9.179985523223877, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.8999999761581421\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.train(data=\"drawings\", epochs=10, imgsz=224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.55  Python-3.11.8 torch-2.2.2+cpu CPU (12th Gen Intel Core(TM) i5-1240P)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\train... found 40 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\val... found 20 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\val... 20 images, 0 corrupt: 100%|██████████| 20/20 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 2/2 [00:00<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        0.9          1\n",
      "Speed: 0.0ms preprocess, 10.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train22\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
       "\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x0000028FEA48F550>\n",
       "curves: []\n",
       "curves_results: []\n",
       "fitness: 0.949999988079071\n",
       "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
       "results_dict: {'metrics/accuracy_top1': 0.8999999761581421, 'metrics/accuracy_top5': 1.0, 'fitness': 0.949999988079071}\n",
       "save_dir: WindowsPath('runs/classify/train22')\n",
       "speed: {'preprocess': 0.0, 'inference': 10.924327373504639, 'loss': 0.0, 'postprocess': 0.0}\n",
       "task: 'classify'\n",
       "top1: 0.8999999761581421\n",
       "top5: 1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\test\\202.jpg: 224x224 Bad 0.59, Good 0.41, 82.5ms\n",
      "Speed: 37.0ms preprocess, 82.5ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: None\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'Bad', 1: 'Good'}\n",
      "obb: None\n",
      "orig_img: array([[[215, 204, 206],\n",
      "        [215, 204, 206],\n",
      "        [216, 205, 207],\n",
      "        ...,\n",
      "        [254, 254, 254],\n",
      "        [254, 254, 254],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[215, 204, 206],\n",
      "        [215, 204, 206],\n",
      "        [216, 205, 207],\n",
      "        ...,\n",
      "        [254, 254, 254],\n",
      "        [254, 254, 254],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       [[214, 203, 205],\n",
      "        [215, 204, 206],\n",
      "        [216, 205, 207],\n",
      "        ...,\n",
      "        [254, 254, 254],\n",
      "        [254, 254, 254],\n",
      "        [255, 255, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[145, 139, 196],\n",
      "        [146, 140, 197],\n",
      "        [146, 140, 197],\n",
      "        ...,\n",
      "        [112, 113, 163],\n",
      "        [112, 113, 163],\n",
      "        [112, 113, 163]],\n",
      "\n",
      "       [[145, 139, 196],\n",
      "        [145, 139, 196],\n",
      "        [146, 140, 197],\n",
      "        ...,\n",
      "        [111, 112, 162],\n",
      "        [111, 112, 162],\n",
      "        [111, 112, 162]],\n",
      "\n",
      "       [[145, 139, 196],\n",
      "        [145, 139, 196],\n",
      "        [145, 139, 196],\n",
      "        ...,\n",
      "        [110, 111, 161],\n",
      "        [110, 111, 161],\n",
      "        [110, 111, 161]]], dtype=uint8)\n",
      "orig_shape: (720, 1280)\n",
      "path: 'c:\\\\Users\\\\SAYANTANI DEY\\\\Desktop\\\\IITP\\\\Doodles Project\\\\drawings\\\\test\\\\202.jpg'\n",
      "probs: ultralytics.engine.results.Probs object\n",
      "save_dir: 'runs\\\\classify\\\\train23'\n",
      "speed: {'preprocess': 37.00089454650879, 'inference': 82.51142501831055, 'postprocess': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "results = model(\"drawings/test/202.jpg\")  \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\test\\202.jpg: 224x224 Bad 0.59, Good 0.41, 27.1ms\n",
      "Speed: 12.8ms preprocess, 27.1ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Prediction: Bad (58.81%)\n"
     ]
    }
   ],
   "source": [
    "results = model(\"drawings/test/202.jpg\")\n",
    "\n",
    "# Extract class probabilities\n",
    "probs = results[0].probs  # Get probabilities object\n",
    "class_index = probs.top1  # Get top predicted class index\n",
    "confidence = probs.top1conf  # Get confidence score\n",
    "\n",
    "# Get class names from the model\n",
    "class_name = results[0].names[class_index]\n",
    "\n",
    "# Print clear output\n",
    "print(f\"Prediction: {class_name} ({confidence*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\test\\204.jpg: 224x224 Good 0.61, Bad 0.39, 45.4ms\n",
      "Speed: 0.0ms preprocess, 45.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Prediction: Good (60.81%)\n"
     ]
    }
   ],
   "source": [
    "results = model(\"drawings/test/204.jpg\")\n",
    "# Get class names from the model\n",
    "class_name = results[0].names[class_index]\n",
    "# Extract class probabilities\n",
    "probs = results[0].probs  # Get probabilities object\n",
    "class_index = probs.top1  # Get top predicted class index\n",
    "confidence = probs.top1conf  # Get confidence score\n",
    "\n",
    "# Get class names from the model\n",
    "class_name = results[0].names[class_index]\n",
    "\n",
    "# Print clear output\n",
    "print(f\"Prediction: {class_name} ({confidence*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\SAYANTANI DEY\\Desktop\\IITP\\Doodles Project\\drawings\\test\\205.jpg: 224x224 Good 0.54, Bad 0.46, 35.6ms\n",
      "Speed: 47.7ms preprocess, 35.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Prediction: Good (54.40%)\n"
     ]
    }
   ],
   "source": [
    "results = model(\"drawings/test/205.jpg\")\n",
    "\n",
    "# Extract class probabilities\n",
    "probs = results[0].probs  # Get probabilities object\n",
    "class_index = probs.top1  # Get top predicted class index\n",
    "confidence = probs.top1conf  # Get confidence score\n",
    "\n",
    "# Get class names from the model\n",
    "class_name = results[0].names[class_index]\n",
    "\n",
    "# Print clear output\n",
    "print(f\"Prediction: {class_name} ({confidence*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.55  Python-3.11.8 torch-2.2.2+cpu CPU (12th Gen Intel Core(TM) i5-1240P)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\classify\\train2\\weights\\best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 2) (2.8 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim', 'onnxruntime'] not found, attempting AutoUpdate...\n",
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.17.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Collecting onnxslim\n",
      "  Downloading onnxslim-0.1.48-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.20.1-cp311-cp311-win_amd64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\sayantani dey\\appdata\\roaming\\python\\python311\\site-packages (from onnx>=1.12.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in d:\\anaconda\\envs\\sdc\\lib\\site-packages (from onnx>=1.12.0) (4.25.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\sayantani dey\\appdata\\roaming\\python\\python311\\site-packages (from onnxslim) (1.12)\n",
      "Requirement already satisfied: packaging in c:\\users\\sayantani dey\\appdata\\roaming\\python\\python311\\site-packages (from onnxslim) (24.0)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in d:\\anaconda\\envs\\sdc\\lib\\site-packages (from onnxruntime) (24.3.25)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sayantani dey\\appdata\\roaming\\python\\python311\\site-packages (from sympy->onnxslim) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading onnx-1.17.0-cp311-cp311-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 14.5/14.5 MB 72.8 kB/s eta 0:00:00\n",
      "Downloading onnxslim-0.1.48-py3-none-any.whl (142 kB)\n",
      "Downloading onnxruntime-1.20.1-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 11.3/11.3 MB 904.6 kB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pyreadline3, onnx, onnxslim, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-1.20.1 onnxslim-0.1.48 pyreadline3-3.5.4\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  246.7s, installed 3 packages: ['onnx>=1.12.0', 'onnxslim', 'onnxruntime']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export failure  262.4s: DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43monnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Export in ONNX format (for AI applications)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\sdc\\Lib\\site-packages\\ultralytics\\engine\\model.py:738\u001b[0m, in \u001b[0;36mModel.export\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    730\u001b[0m custom \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgsz\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgsz\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    736\u001b[0m }  \u001b[38;5;66;03m# method defaults\u001b[39;00m\n\u001b[0;32m    737\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\sdc\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:387\u001b[0m, in \u001b[0;36mExporter.__call__\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    385\u001b[0m     f[\u001b[38;5;241m1\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_engine(dla\u001b[38;5;241m=\u001b[39mdla)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m onnx:  \u001b[38;5;66;03m# ONNX\u001b[39;00m\n\u001b[1;32m--> 387\u001b[0m     f[\u001b[38;5;241m2\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xml:  \u001b[38;5;66;03m# OpenVINO\u001b[39;00m\n\u001b[0;32m    389\u001b[0m     f[\u001b[38;5;241m3\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_openvino()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\sdc\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:170\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export failure ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\sdc\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:165\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Profile() \u001b[38;5;28;01mas\u001b[39;00m dt:\n\u001b[1;32m--> 165\u001b[0m         f, model \u001b[38;5;241m=\u001b[39m \u001b[43minner_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export success ✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_size(f)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f, model\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\sdc\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:480\u001b[0m, in \u001b[0;36mExporter.export_onnx\u001b[1;34m(self, prefix)\u001b[0m\n\u001b[0;32m    478\u001b[0m     requirements \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnxslim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnxruntime\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-gpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    479\u001b[0m check_requirements(requirements)\n\u001b[1;32m--> 480\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    482\u001b[0m opset_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mopset \u001b[38;5;129;01mor\u001b[39;00m get_latest_opset()\n\u001b[0;32m    483\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m starting export with onnx \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m opset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopset_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\sdc\\Lib\\site-packages\\onnx\\__init__.py:77\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IO, Literal, Union\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx_cpp2py_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ONNX_ML\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternal_data_helper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     79\u001b[0m     load_external_data_for_model,\n\u001b[0;32m     80\u001b[0m     write_external_data_tensors,\n\u001b[0;32m     81\u001b[0m     convert_model_to_external_data,\n\u001b[0;32m     82\u001b[0m )\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx_pb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     84\u001b[0m     AttributeProto,\n\u001b[0;32m     85\u001b[0m     EXPERIMENTAL,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m     Version,\n\u001b[0;32m    112\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing onnx_cpp2py_export: A dynamic link library (DLL) initialization routine failed."
     ]
    }
   ],
   "source": [
    "model.export(format=\"onnx\")  # Export in ONNX format (for AI applications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
